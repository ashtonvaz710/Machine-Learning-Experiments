{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as plt\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import euclidean_distances, cosine_distances\n",
    "from pprint import pprint\n",
    "from collections import Counter\n",
    "from random import randrange\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates absolute path\n",
    "def abspath(path, *paths):\n",
    "    fpath = os.path.join(os.getcwd(), os.pardir, path)\n",
    "\n",
    "    for p in paths:\n",
    "        fpath = os.path.join(fpath, p)\n",
    "    return fpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_metrics(pred_labels, true_labels=None):\n",
    "    if true_labels is not None:\n",
    "        N = len(pred_labels)\n",
    "\n",
    "        cluster_labels = {}\n",
    "        for i in range(len(pred_labels)):\n",
    "            cluster_labels.setdefault(pred_labels[i], []).append(true_labels[i])\n",
    "\n",
    "        cluster_labels.pop('Noise', None)\n",
    "        K = len(cluster_labels)\n",
    "\n",
    "        # Store list of labels as a Counter\n",
    "        for key,value in cluster_labels.items():\n",
    "            cluster_labels[key] = Counter(value)\n",
    "\n",
    "        # Calculate purity\n",
    "        purity = 0\n",
    "        for cluster in cluster_labels:\n",
    "            purity += max(cluster_labels[cluster].values())\n",
    "\n",
    "        purity /= N\n",
    "\n",
    "        # Calculate gini index\n",
    "        gini_index = 0\n",
    "        for key,value in cluster_labels.items():\n",
    "            gini = 0\n",
    "            for k,v in value.items():\n",
    "                gini += (v / sum(cluster_labels[key].values())) ** 2\n",
    "            gini_index += 1 - gini\n",
    "\n",
    "        gini_index /= K if K != 0 else 1\n",
    "\n",
    "        # Final result\n",
    "        print('Purity -', round(purity, 4), 'Gini Index -', round(gini_index, 4))\n",
    "\n",
    "    print('No. of clusters -', len(Counter(pred_labels)))\n",
    "    print(Counter(pred_labels), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k - index of current data point in data\n",
    "# e - epsilon\n",
    "def find_neighbors(k, e, distance_matrix):\n",
    "    N = []      # Neighbors\n",
    "    \n",
    "    for i in range(len(distance_matrix[k])):\n",
    "        if distance_matrix[k][i] <= e and i != k:   # Return neighbors within distance e, except for the point itself\n",
    "            N.append(i)\n",
    "\n",
    "    return N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# e - epsilon\n",
    "# min_pts - min points\n",
    "def dbscan(data, e, min_pts, labels=None):\n",
    "    \n",
    "    distance_matrix = euclidean_distances(data)\n",
    "\n",
    "    clusters = []\n",
    "    for i in range(data.shape[0]):\n",
    "        clusters.append(math.nan)\n",
    "\n",
    "    c = 0   # Cluster label\n",
    "    for i in range(data.shape[0]):\n",
    "\n",
    "        # Skip if already assigned a cluster\n",
    "        if not pd.isnull(clusters[i]):\n",
    "            continue\n",
    "\n",
    "        S = find_neighbors(i, e, distance_matrix)\n",
    "\n",
    "        # Density check - label Noise if no. of neighbors less than min_pts\n",
    "        if len(S) < min_pts:\n",
    "            clusters[i] = 'Noise'\n",
    "            continue\n",
    "\n",
    "        # Next cluster label\n",
    "        c = c + 1\n",
    "\n",
    "        # Add point to the new cluster\n",
    "        clusters[i] = c\n",
    "\n",
    "        # Process every point in neighborhood except the point itself\n",
    "        for j in S:\n",
    "            j = int(j)\n",
    "            if j != i:\n",
    "\n",
    "                # Change noise point to border point \n",
    "                if clusters[j] == 'Noise':\n",
    "                    clusters[j] = c\n",
    "\n",
    "                # Skip if already assigned a cluster\n",
    "                if not pd.isnull([clusters[j]]):\n",
    "                    continue\n",
    "\n",
    "                # Add neighbor to the current cluster\n",
    "                clusters[j] = c\n",
    "\n",
    "                # Get neighbors\n",
    "                N = find_neighbors(j, e, distance_matrix)\n",
    "\n",
    "                # Density check - add new neighbors to seed set if no. of neighbors greater than min_pts\n",
    "                if len(N) >= min_pts:\n",
    "                    for k in N:\n",
    "                        if int(k) != i:\n",
    "                            S.append(k)\n",
    "\n",
    "    # Evaluate results\n",
    "    print('epsilon -', e, 'min_pts -', min_pts)\n",
    "    evaluation_metrics(clusters, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N - size of sample\n",
    "def get_samples(data, N, labels=None):\n",
    "    sampled_data = np.zeros((N, data.shape[1]))\n",
    "    \n",
    "    if labels is None:\n",
    "        for i in range(N):\n",
    "            j = randrange(0, data.shape[0] - 1)\n",
    "            sampled_data[i] = data[j]\n",
    "\n",
    "        return sampled_data\n",
    "        \n",
    "    else:\n",
    "        sampled_labels = []\n",
    "        for i in range(N):\n",
    "            j = randrange(0, data.shape[0] - 1)\n",
    "            sampled_data[i] = data[j]\n",
    "            sampled_labels.append(labels[j])\n",
    "\n",
    "        return (sampled_data, sampled_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ashton\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2728: DtypeWarning: Columns (2,3,4,5,6,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2049280, 7)\n"
     ]
    }
   ],
   "source": [
    "# Fetch data\n",
    "\n",
    "dataset_path = abspath('datasets', 'household_power_consumption.txt')\n",
    "household_dataset = pd.read_csv(dataset_path, sep=';', header=0)\n",
    "household_dataset = household_dataset.values[:, range(2, household_dataset.shape[1])]\n",
    "\n",
    "rows = 0\n",
    "for i in range(household_dataset.shape[0]):\n",
    "    flag = 0\n",
    "    for j in range(household_dataset.shape[1]):\n",
    "        if household_dataset[i][j] == '.' or household_dataset[i][j] == '?' or math.isnan(float(household_dataset[i][j])):\n",
    "            flag = 1\n",
    "            break\n",
    "    \n",
    "    if flag == 0:\n",
    "        rows += 1\n",
    "\n",
    "# Clean data\n",
    "new_dataset = np.zeros((rows, household_dataset.shape[1]))\n",
    "k = 0\n",
    "for i in range(household_dataset.shape[0]):\n",
    "    flag = 0\n",
    "    for j in range(household_dataset.shape[1]):\n",
    "        if household_dataset[i][j] == '.' or household_dataset[i][j] == '?' or math.isnan(float(household_dataset[i][j])):\n",
    "            flag = 1\n",
    "            break\n",
    "    \n",
    "    if flag == 0:\n",
    "        for l in range(household_dataset.shape[1]):\n",
    "            new_dataset[k][l] = float(household_dataset[i][l])\n",
    "        k += 1\n",
    "                    \n",
    "print(new_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epsilon - 1 min_pts - 1\n",
      "No. of clusters - 159\n",
      "Counter({1: 2139, 'Noise': 694, 2: 500, 5: 296, 8: 196, 4: 179, 11: 129, 16: 110, 6: 92, 17: 82, 33: 55, 15: 32, 10: 21, 19: 20, 38: 18, 32: 16, 13: 12, 27: 10, 54: 8, 80: 7, 3: 6, 22: 6, 46: 6, 59: 6, 63: 6, 75: 6, 12: 5, 18: 5, 21: 5, 39: 5, 81: 5, 82: 5, 87: 5, 91: 5, 136: 5, 30: 4, 36: 4, 37: 4, 44: 4, 49: 4, 51: 4, 52: 4, 65: 4, 73: 4, 96: 4, 97: 4, 102: 4, 107: 4, 118: 4, 150: 4, 154: 4, 14: 3, 25: 3, 40: 3, 42: 3, 43: 3, 47: 3, 53: 3, 57: 3, 60: 3, 64: 3, 67: 3, 68: 3, 69: 3, 76: 3, 84: 3, 90: 3, 92: 3, 95: 3, 111: 3, 115: 3, 121: 3, 126: 3, 138: 3, 7: 2, 9: 2, 20: 2, 23: 2, 24: 2, 26: 2, 28: 2, 29: 2, 31: 2, 34: 2, 35: 2, 41: 2, 45: 2, 48: 2, 50: 2, 55: 2, 56: 2, 58: 2, 61: 2, 62: 2, 66: 2, 70: 2, 71: 2, 72: 2, 74: 2, 77: 2, 78: 2, 79: 2, 83: 2, 85: 2, 86: 2, 88: 2, 89: 2, 93: 2, 94: 2, 98: 2, 99: 2, 100: 2, 101: 2, 103: 2, 104: 2, 105: 2, 106: 2, 108: 2, 109: 2, 110: 2, 112: 2, 113: 2, 114: 2, 116: 2, 117: 2, 119: 2, 120: 2, 122: 2, 123: 2, 124: 2, 125: 2, 127: 2, 128: 2, 129: 2, 130: 2, 131: 2, 132: 2, 133: 2, 134: 2, 135: 2, 137: 2, 139: 2, 140: 2, 141: 2, 142: 2, 143: 2, 144: 2, 145: 2, 146: 2, 147: 2, 148: 2, 149: 2, 151: 2, 152: 2, 153: 2, 155: 2, 156: 2, 157: 2, 158: 2}) \n",
      "\n",
      "epsilon - 2 min_pts - 1\n",
      "No. of clusters - 30\n",
      "Counter({1: 3176, 2: 1459, 'Noise': 197, 3: 32, 11: 25, 7: 24, 4: 22, 16: 8, 24: 5, 27: 4, 8: 3, 9: 3, 12: 3, 19: 3, 21: 3, 22: 3, 26: 3, 28: 3, 5: 2, 6: 2, 10: 2, 13: 2, 14: 2, 15: 2, 17: 2, 18: 2, 20: 2, 23: 2, 25: 2, 29: 2}) \n",
      "\n",
      "epsilon - 3 min_pts - 1\n",
      "No. of clusters - 24\n",
      "Counter({1: 4664, 'Noise': 118, 2: 52, 10: 30, 6: 29, 3: 28, 13: 11, 17: 11, 7: 10, 14: 6, 4: 4, 8: 4, 11: 4, 12: 4, 9: 3, 15: 3, 21: 3, 22: 3, 23: 3, 5: 2, 16: 2, 18: 2, 19: 2, 20: 2}) \n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-a2d11f800358>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m         \u001b[0mdbscan\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msampled_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'------------------------------'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-2c373b3cc988>\u001b[0m in \u001b[0;36mdbscan\u001b[1;34m(data, e, min_pts, labels)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdbscan\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_pts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mdistance_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0meuclidean_distances\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mclusters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ashton\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36meuclidean_distances\u001b[1;34m(X, Y, Y_norm_squared, squared, X_norm_squared)\u001b[0m\n\u001b[0;32m    245\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    246\u001b[0m     \u001b[0mdistances\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdense_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 247\u001b[1;33m     \u001b[0mdistances\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    248\u001b[0m     \u001b[0mdistances\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mXX\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m     \u001b[0mdistances\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mYY\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sampled_data = get_samples(new_dataset, 5000)\n",
    "for p in [1,3,5]:\n",
    "    for e in [1,2,3,4,5,6]:\n",
    "        dbscan(data=sampled_data, e=e, min_pts=p)\n",
    "    print('------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
