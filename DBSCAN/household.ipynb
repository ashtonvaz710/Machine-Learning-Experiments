{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as plt\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import euclidean_distances, cosine_distances\n",
    "from pprint import pprint\n",
    "from collections import Counter\n",
    "from random import randrange\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates absolute path\n",
    "def abspath(path, *paths):\n",
    "    fpath = os.path.join(os.getcwd(), os.pardir, path)\n",
    "\n",
    "    for p in paths:\n",
    "        fpath = os.path.join(fpath, p)\n",
    "    return fpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_metrics(pred_labels, true_labels=None):\n",
    "    if true_labels is not None:\n",
    "        N = len(pred_labels)\n",
    "\n",
    "        cluster_labels = {}\n",
    "        for i in range(len(pred_labels)):\n",
    "            cluster_labels.setdefault(pred_labels[i], []).append(true_labels[i])\n",
    "\n",
    "        cluster_labels.pop('Noise', None)\n",
    "        K = len(cluster_labels)\n",
    "\n",
    "        # Store list of labels as a Counter\n",
    "        for key,value in cluster_labels.items():\n",
    "            cluster_labels[key] = Counter(value)\n",
    "\n",
    "        # Calculate purity\n",
    "        purity = 0\n",
    "        for cluster in cluster_labels:\n",
    "            purity += max(cluster_labels[cluster].values())\n",
    "\n",
    "        purity /= N\n",
    "\n",
    "        # Calculate gini index\n",
    "        gini_index = 0\n",
    "        for key,value in cluster_labels.items():\n",
    "            gini = 0\n",
    "            for k,v in value.items():\n",
    "                gini += (v / sum(cluster_labels[key].values())) ** 2\n",
    "            gini_index += 1 - gini\n",
    "\n",
    "        gini_index /= K if K != 0 else 1\n",
    "\n",
    "        # Final result\n",
    "        print('Purity -', round(purity, 4), 'Gini Index -', round(gini_index, 4))\n",
    "\n",
    "    print('No. of clusters -', len(Counter(pred_labels)))\n",
    "    print(Counter(pred_labels), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k - index of current data point in data\n",
    "# e - epsilon\n",
    "def find_neighbors(k, e, distance_matrix):\n",
    "    N = []      # Neighbors\n",
    "    \n",
    "    for i in range(len(distance_matrix[k])):\n",
    "        if distance_matrix[k][i] <= e and i != k:   # Return neighbors within distance e, except for the point itself\n",
    "            N.append(i)\n",
    "\n",
    "    return N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# e - epsilon\n",
    "# min_pts - min points\n",
    "def dbscan(data, e, min_pts, labels=None):\n",
    "    \n",
    "    distance_matrix = euclidean_distances(data)\n",
    "\n",
    "    clusters = []\n",
    "    for i in range(data.shape[0]):\n",
    "        clusters.append(math.nan)\n",
    "\n",
    "    c = 0   # Cluster label\n",
    "    for i in range(data.shape[0]):\n",
    "\n",
    "        # Skip if already assigned a cluster\n",
    "        if not pd.isnull(clusters[i]):\n",
    "            continue\n",
    "\n",
    "        S = find_neighbors(i, e, distance_matrix)\n",
    "\n",
    "        # Density check - label Noise if no. of neighbors less than min_pts\n",
    "        if len(S) < min_pts:\n",
    "            clusters[i] = 'Noise'\n",
    "            continue\n",
    "\n",
    "        # Next cluster label\n",
    "        c = c + 1\n",
    "\n",
    "        # Add point to the new cluster\n",
    "        clusters[i] = c\n",
    "\n",
    "        # Process every point in neighborhood except the point itself\n",
    "        for j in S:\n",
    "            j = int(j)\n",
    "            if j != i:\n",
    "\n",
    "                # Change noise point to border point \n",
    "                if clusters[j] == 'Noise':\n",
    "                    clusters[j] = c\n",
    "\n",
    "                # Skip if already assigned a cluster\n",
    "                if not pd.isnull([clusters[j]]):\n",
    "                    continue\n",
    "\n",
    "                # Add neighbor to the current cluster\n",
    "                clusters[j] = c\n",
    "\n",
    "                # Get neighbors\n",
    "                N = find_neighbors(j, e, distance_matrix)\n",
    "\n",
    "                # Density check - add new neighbors to seed set if no. of neighbors greater than min_pts\n",
    "                if len(N) >= min_pts:\n",
    "                    for k in N:\n",
    "                        if int(k) != i:\n",
    "                            S.append(k)\n",
    "\n",
    "    # Evaluate results\n",
    "    print('epsilon -', e, 'min_pts -', min_pts)\n",
    "    evaluation_metrics(clusters, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N - size of sample\n",
    "def get_samples(data, N, labels=None):\n",
    "    sampled_data = np.zeros((N, data.shape[1]))\n",
    "    \n",
    "    if labels is None:\n",
    "        for i in range(N):\n",
    "            j = randrange(0, data.shape[0] - 1)\n",
    "            sampled_data[i] = data[j]\n",
    "\n",
    "        return sampled_data\n",
    "        \n",
    "    else:\n",
    "        sampled_labels = []\n",
    "        for i in range(N):\n",
    "            j = randrange(0, data.shape[0] - 1)\n",
    "            sampled_data[i] = data[j]\n",
    "            sampled_labels.append(labels[j])\n",
    "\n",
    "        return (sampled_data, sampled_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ashton\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2728: DtypeWarning: Columns (2,3,4,5,6,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2049280, 7)\n"
     ]
    }
   ],
   "source": [
    "# Fetch data\n",
    "\n",
    "dataset_path = abspath('datasets', 'household_power_consumption.txt')\n",
    "household_dataset = pd.read_csv(dataset_path, sep=';', header=0)\n",
    "household_dataset = household_dataset.values[:, range(2, household_dataset.shape[1])]\n",
    "\n",
    "rows = 0\n",
    "for i in range(household_dataset.shape[0]):\n",
    "    flag = 0\n",
    "    for j in range(household_dataset.shape[1]):\n",
    "        if household_dataset[i][j] == '.' or household_dataset[i][j] == '?' or math.isnan(float(household_dataset[i][j])):\n",
    "            flag = 1\n",
    "            break\n",
    "    \n",
    "    if flag == 0:\n",
    "        rows += 1\n",
    "\n",
    "# Clean data\n",
    "new_dataset = np.zeros((rows, household_dataset.shape[1]))\n",
    "k = 0\n",
    "for i in range(household_dataset.shape[0]):\n",
    "    flag = 0\n",
    "    for j in range(household_dataset.shape[1]):\n",
    "        if household_dataset[i][j] == '.' or household_dataset[i][j] == '?' or math.isnan(float(household_dataset[i][j])):\n",
    "            flag = 1\n",
    "            break\n",
    "    \n",
    "    if flag == 0:\n",
    "        for l in range(household_dataset.shape[1]):\n",
    "            new_dataset[k][l] = float(household_dataset[i][l])\n",
    "        k += 1\n",
    "                    \n",
    "print(new_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epsilon - 2 min_pts - 1\n",
      "No. of clusters - 36\n",
      "Counter({1: 3186, 2: 1406, 'Noise': 217, 6: 54, 8: 32, 7: 10, 17: 9, 3: 8, 12: 6, 29: 6, 11: 5, 15: 5, 16: 4, 5: 3, 13: 3, 19: 3, 21: 3, 24: 3, 25: 3, 4: 2, 9: 2, 10: 2, 14: 2, 18: 2, 20: 2, 22: 2, 23: 2, 26: 2, 27: 2, 28: 2, 30: 2, 31: 2, 32: 2, 33: 2, 34: 2, 35: 2}) \n",
      "\n",
      "epsilon - 4 min_pts - 1\n",
      "No. of clusters - 21\n",
      "Counter({1: 4705, 6: 65, 2: 54, 'Noise': 51, 3: 37, 10: 19, 5: 17, 4: 14, 17: 6, 7: 5, 15: 4, 11: 3, 13: 3, 18: 3, 8: 2, 9: 2, 12: 2, 14: 2, 16: 2, 19: 2, 20: 2}) \n",
      "\n",
      "------------------------------\n",
      "epsilon - 2 min_pts - 3\n",
      "No. of clusters - 16\n",
      "Counter({1: 3085, 2: 1405, 'Noise': 278, 3: 100, 4: 49, 5: 29, 9: 10, 12: 9, 7: 6, 14: 6, 6: 4, 8: 4, 13: 4, 11: 4, 15: 4, 10: 3}) \n",
      "\n",
      "epsilon - 4 min_pts - 3\n",
      "No. of clusters - 11\n",
      "Counter({1: 4704, 'Noise': 80, 4: 65, 3: 54, 7: 37, 8: 18, 6: 15, 2: 12, 9: 6, 5: 5, 10: 4}) \n",
      "\n",
      "------------------------------\n",
      "epsilon - 2 min_pts - 5\n",
      "No. of clusters - 9\n",
      "Counter({1: 3077, 2: 1402, 'Noise': 333, 3: 97, 5: 41, 4: 25, 6: 10, 7: 9, 8: 6}) \n",
      "\n",
      "epsilon - 4 min_pts - 5\n",
      "No. of clusters - 9\n",
      "Counter({1: 4702, 'Noise': 109, 3: 65, 2: 46, 4: 37, 5: 13, 7: 13, 6: 9, 8: 6}) \n",
      "\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "sampled_data = get_samples(new_dataset, 5000)\n",
    "for p in [1,3,5]:\n",
    "    for e in [2,4]:\n",
    "        dbscan(data=sampled_data, e=e, min_pts=p)\n",
    "    print('------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
