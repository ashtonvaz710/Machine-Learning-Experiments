{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates absolute path\n",
    "def abspath(path, *paths):\n",
    "    fpath = os.path.join(os.getcwd(), os.pardir, path)\n",
    "\n",
    "    for p in paths:\n",
    "        fpath = os.path.join(fpath, p)\n",
    "    return fpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2_logistic_regression(train_data, test_data, train_labels, test_labels):\n",
    "    \n",
    "    # Train model\n",
    "    model = LogisticRegression(penalty='l2', random_state=42)\n",
    "    model.fit(train_data, train_labels)    \n",
    "    \n",
    "    # Extract top features from model\n",
    "    importances = model.coef_\n",
    "    \n",
    "    for i in range(len(importances)):\n",
    "        indices = np.argsort(importances[i])[::-1]\n",
    "\n",
    "        print('\\nFeature ranking for label ' + str(i) + ':') if len(importances) > 1 else print('Feature ranking:')\n",
    "        for f in range(30):\n",
    "            print('%d. Feature %d (%f)' % (f + 1, indices[f], importances[i][indices[f]]))\n",
    "\n",
    "    # Test model\n",
    "    y_train_pred = model.predict(train_data)\n",
    "    y_test_pred = model.predict(test_data)\n",
    "\n",
    "    # Evaluate model\n",
    "    print('\\nLogistic Regression - \\nTrain Accuracy: ', round(np.sum(y_train_pred == train_labels) / train_data.shape[0], 4))\n",
    "    print('Test Accuracy: ', round(np.sum(y_test_pred == test_labels) / test_data.shape[0], 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree_classifier(train_data, test_data, train_labels, test_labels):\n",
    "\n",
    "    # Train model\n",
    "    for model in [\n",
    "        DecisionTreeClassifier(random_state=42), \n",
    "        DecisionTreeClassifier(random_state=42, max_depth=10), \n",
    "        DecisionTreeClassifier(random_state=42, min_samples_leaf=2), \n",
    "        DecisionTreeClassifier(random_state=42, min_samples_split=3)\n",
    "    ]:\n",
    "        \n",
    "        model.fit(train_data, train_labels)\n",
    "\n",
    "        # Extract top features from model\n",
    "        importances = model.feature_importances_\n",
    "        indices = np.argsort(importances)[::-1]\n",
    "\n",
    "        print('Feature ranking:')\n",
    "        for f in range(30):\n",
    "            print('%d. Feature %d (%f)' % (f + 1, indices[f], importances[indices[f]]))\n",
    "\n",
    "        # Test model\n",
    "        y_train_pred = model.predict(train_data)\n",
    "        y_test_pred = model.predict(test_data)\n",
    "\n",
    "        # Evaluate model\n",
    "        print('\\nDecision Tree - \\nTrain Accuracy: ', round(np.sum(y_train_pred == train_labels) / train_data.shape[0], 4))\n",
    "        print('Test Accuracy: ', round(np.sum(y_test_pred == test_labels) / test_data.shape[0], 4))\n",
    "        print('-------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ashton\\Documents\\GitHub\\Machine-Learning-Experiments\\Feature Extraction\\Feature Selection\\..\\..\\datasets\\spambase.data\n",
      "(4601, 58)\n",
      "(4601, 57)\n",
      "(4601,)\n"
     ]
    }
   ],
   "source": [
    "# Fetch data\n",
    "spambase_path = abspath('..', 'datasets', 'spambase.data')\n",
    "print(spambase_path)\n",
    "spambase_dataset = np.loadtxt(open(spambase_path, 'rb'), delimiter=',')\n",
    "\n",
    "# Data and labels\n",
    "spambase_data = spambase_dataset[:, list(range(0, spambase_dataset.shape[1] - 1))]\n",
    "spambase_labels = spambase_dataset[:, spambase_dataset.shape[1] - 1]\n",
    "\n",
    "print(spambase_dataset.shape)\n",
    "print(spambase_data.shape)\n",
    "print(spambase_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3680, 57)\n",
      "(921, 57)\n"
     ]
    }
   ],
   "source": [
    "# Split into training and testing datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(spambase_data, spambase_labels, test_size=0.20, random_state=42)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n",
      "1. Feature 52 (3.584241)\n",
      "2. Feature 22 (2.325232)\n",
      "3. Feature 6 (2.196551)\n",
      "4. Feature 14 (1.476576)\n",
      "5. Feature 53 (1.111259)\n",
      "6. Feature 35 (1.021773)\n",
      "7. Feature 15 (1.012616)\n",
      "8. Feature 16 (0.967225)\n",
      "9. Feature 19 (0.940994)\n",
      "10. Feature 3 (0.721762)\n",
      "11. Feature 8 (0.631920)\n",
      "12. Feature 4 (0.613005)\n",
      "13. Feature 5 (0.607756)\n",
      "14. Feature 7 (0.513041)\n",
      "15. Feature 23 (0.353613)\n",
      "16. Feature 27 (0.333023)\n",
      "17. Feature 51 (0.246687)\n",
      "18. Feature 20 (0.233609)\n",
      "19. Feature 21 (0.229864)\n",
      "20. Feature 2 (0.158968)\n",
      "21. Feature 33 (0.140470)\n",
      "22. Feature 9 (0.094108)\n",
      "23. Feature 18 (0.092446)\n",
      "24. Feature 13 (0.087026)\n",
      "25. Feature 17 (0.066873)\n",
      "26. Feature 31 (0.058252)\n",
      "27. Feature 12 (0.008956)\n",
      "28. Feature 55 (0.006827)\n",
      "29. Feature 56 (0.000874)\n",
      "30. Feature 54 (-0.011644)\n",
      "\n",
      "Logistic Regression - \n",
      "Train Accuracy:  0.9323\n",
      "Test Accuracy:  0.9229\n"
     ]
    }
   ],
   "source": [
    "l2_logistic_regression(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n",
      "1. Feature 52 (0.339152)\n",
      "2. Feature 6 (0.161860)\n",
      "3. Feature 51 (0.084357)\n",
      "4. Feature 54 (0.054901)\n",
      "5. Feature 24 (0.052564)\n",
      "6. Feature 55 (0.032372)\n",
      "7. Feature 15 (0.031038)\n",
      "8. Feature 26 (0.024413)\n",
      "9. Feature 56 (0.018537)\n",
      "10. Feature 45 (0.016740)\n",
      "11. Feature 18 (0.015898)\n",
      "12. Feature 4 (0.015344)\n",
      "13. Feature 16 (0.011050)\n",
      "14. Feature 11 (0.010865)\n",
      "15. Feature 23 (0.010063)\n",
      "16. Feature 34 (0.008090)\n",
      "17. Feature 20 (0.007849)\n",
      "18. Feature 8 (0.006836)\n",
      "19. Feature 17 (0.006442)\n",
      "20. Feature 35 (0.006228)\n",
      "21. Feature 9 (0.006214)\n",
      "22. Feature 7 (0.006209)\n",
      "23. Feature 44 (0.005744)\n",
      "24. Feature 48 (0.005350)\n",
      "25. Feature 10 (0.005001)\n",
      "26. Feature 5 (0.004893)\n",
      "27. Feature 12 (0.004819)\n",
      "28. Feature 38 (0.004345)\n",
      "29. Feature 49 (0.003510)\n",
      "30. Feature 47 (0.003171)\n",
      "\n",
      "Decision Tree - \n",
      "Train Accuracy:  0.9995\n",
      "Test Accuracy:  0.9197\n",
      "-------------------------------------------\n",
      "Feature ranking:\n",
      "1. Feature 52 (0.379143)\n",
      "2. Feature 6 (0.181890)\n",
      "3. Feature 51 (0.090861)\n",
      "4. Feature 24 (0.057281)\n",
      "5. Feature 54 (0.047276)\n",
      "6. Feature 15 (0.033506)\n",
      "7. Feature 26 (0.023767)\n",
      "8. Feature 55 (0.023320)\n",
      "9. Feature 45 (0.015929)\n",
      "10. Feature 56 (0.015697)\n",
      "11. Feature 16 (0.014301)\n",
      "12. Feature 4 (0.013712)\n",
      "13. Feature 18 (0.009422)\n",
      "14. Feature 23 (0.009101)\n",
      "15. Feature 34 (0.008134)\n",
      "16. Feature 7 (0.006986)\n",
      "17. Feature 38 (0.005965)\n",
      "18. Feature 8 (0.005402)\n",
      "19. Feature 44 (0.005150)\n",
      "20. Feature 12 (0.004742)\n",
      "21. Feature 17 (0.004160)\n",
      "22. Feature 35 (0.004008)\n",
      "23. Feature 25 (0.003957)\n",
      "24. Feature 48 (0.003841)\n",
      "25. Feature 10 (0.003180)\n",
      "26. Feature 11 (0.003101)\n",
      "27. Feature 41 (0.002681)\n",
      "28. Feature 20 (0.002659)\n",
      "29. Feature 47 (0.002418)\n",
      "30. Feature 36 (0.002388)\n",
      "\n",
      "Decision Tree - \n",
      "Train Accuracy:  0.9707\n",
      "Test Accuracy:  0.9262\n",
      "-------------------------------------------\n",
      "Feature ranking:\n",
      "1. Feature 52 (0.352218)\n",
      "2. Feature 6 (0.161788)\n",
      "3. Feature 51 (0.091074)\n",
      "4. Feature 54 (0.054158)\n",
      "5. Feature 24 (0.054147)\n",
      "6. Feature 15 (0.035955)\n",
      "7. Feature 55 (0.033670)\n",
      "8. Feature 26 (0.025211)\n",
      "9. Feature 45 (0.017307)\n",
      "10. Feature 56 (0.016331)\n",
      "11. Feature 4 (0.016136)\n",
      "12. Feature 18 (0.013255)\n",
      "13. Feature 16 (0.011443)\n",
      "14. Feature 17 (0.010940)\n",
      "15. Feature 11 (0.009813)\n",
      "16. Feature 7 (0.007777)\n",
      "17. Feature 34 (0.007555)\n",
      "18. Feature 35 (0.007420)\n",
      "19. Feature 23 (0.007308)\n",
      "20. Feature 44 (0.005943)\n",
      "21. Feature 48 (0.005590)\n",
      "22. Feature 20 (0.004881)\n",
      "23. Feature 9 (0.004787)\n",
      "24. Feature 38 (0.004541)\n",
      "25. Feature 10 (0.004350)\n",
      "26. Feature 8 (0.003945)\n",
      "27. Feature 12 (0.003875)\n",
      "28. Feature 49 (0.003478)\n",
      "29. Feature 36 (0.002814)\n",
      "30. Feature 25 (0.002592)\n",
      "\n",
      "Decision Tree - \n",
      "Train Accuracy:  0.9807\n",
      "Test Accuracy:  0.9045\n",
      "-------------------------------------------\n",
      "Feature ranking:\n",
      "1. Feature 52 (0.342867)\n",
      "2. Feature 6 (0.157137)\n",
      "3. Feature 51 (0.082871)\n",
      "4. Feature 54 (0.061386)\n",
      "5. Feature 24 (0.051670)\n",
      "6. Feature 55 (0.034582)\n",
      "7. Feature 15 (0.034085)\n",
      "8. Feature 26 (0.024046)\n",
      "9. Feature 56 (0.016482)\n",
      "10. Feature 45 (0.016237)\n",
      "11. Feature 4 (0.015670)\n",
      "12. Feature 17 (0.014310)\n",
      "13. Feature 18 (0.011295)\n",
      "14. Feature 16 (0.011046)\n",
      "15. Feature 23 (0.010757)\n",
      "16. Feature 7 (0.008132)\n",
      "17. Feature 11 (0.007491)\n",
      "18. Feature 34 (0.007292)\n",
      "19. Feature 35 (0.007150)\n",
      "20. Feature 9 (0.005845)\n",
      "21. Feature 20 (0.005661)\n",
      "22. Feature 48 (0.005396)\n",
      "23. Feature 8 (0.004843)\n",
      "24. Feature 10 (0.004755)\n",
      "25. Feature 38 (0.004383)\n",
      "26. Feature 44 (0.004270)\n",
      "27. Feature 12 (0.003979)\n",
      "28. Feature 25 (0.003975)\n",
      "29. Feature 49 (0.003938)\n",
      "30. Feature 0 (0.003284)\n",
      "\n",
      "Decision Tree - \n",
      "Train Accuracy:  0.9954\n",
      "Test Accuracy:  0.9121\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "decision_tree_classifier(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
